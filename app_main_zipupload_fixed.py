import streamlit as st
import pandas as pd
import tempfile
import zipfile
import os
import re
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows

st.set_page_config(page_title="(ì£¼)ê±´í™” ë“±ê¸°ë¶€ë“±ë³¸ Excel í†µí•©ê¸°", layout="wide")

password = st.text_input('ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”', type='password')
if password != '1220':
    st.warning('ì˜¬ë°”ë¥¸ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.')
    st.stop()

st.title("ğŸ“¦ (ì£¼)ê±´í™” ë“±ê¸°ë¶€ë“±ë³¸ í†µí•©ë¶„ì„ê¸°")
st.markdown("""
ì••ì¶•íŒŒì¼(.zip) ì•ˆì˜ í´ë” êµ¬ì¡°ì™€ ê´€ê³„ì—†ì´ ëª¨ë“  ì—‘ì…€ íŒŒì¼ì„ ìë™ ë¶„ì„í•©ë‹ˆë‹¤.
""")

uploaded_zip = st.file_uploader("ğŸ“ .zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ë‚´ë¶€ì— .xlsx íŒŒì¼ í¬í•¨)", type=["zip"])
run_button = st.button("ë¶„ì„ ì‹œì‘")

def merge_adjacent_cells(row_series, max_gap=3):
    """
    ì¸ì ‘í•œ ì…€ë“¤ì„ ë³‘í•©í•˜ì—¬ í•˜ë‚˜ì˜ ì˜ë¯¸ìˆëŠ” ë‹¨ìœ„ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜
    ì–‡ì€ ì„ ìœ¼ë¡œ ë‚˜ë‰œ ì…€ë“¤ì„ í†µí•©
    """
    merged_row = row_series.copy()
    row_dict = row_series.to_dict()
    
    # ë¹ˆ ì…€ì´ ì•„ë‹Œ ì…€ë“¤ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ê¸°
    non_empty_indices = [idx for idx, val in row_dict.items() if str(val).strip()]
    
    # ì—°ì†ëœ ì…€ë“¤ì„ ê·¸ë£¹í™”
    groups = []
    current_group = []
    
    for i, idx in enumerate(non_empty_indices):
        if not current_group:
            current_group = [idx]
        else:
            # ì´ì „ ì¸ë±ìŠ¤ì™€ì˜ ê±°ë¦¬ê°€ max_gap ì´í•˜ë©´ ê°™ì€ ê·¸ë£¹
            if idx - current_group[-1] <= max_gap:
                current_group.append(idx)
            else:
                # ìƒˆë¡œìš´ ê·¸ë£¹ ì‹œì‘
                groups.append(current_group)
                current_group = [idx]
    
    if current_group:
        groups.append(current_group)
    
    # ê° ê·¸ë£¹ ë‚´ì˜ ì…€ë“¤ì„ ë³‘í•©
    for group in groups:
        if len(group) > 1:
            # ê·¸ë£¹ ë‚´ ëª¨ë“  ê°’ì„ ì—°ê²°
            merged_value = ""
            for idx in group:
                val = str(row_dict.get(idx, "")).strip()
                if val:
                    if merged_value and not merged_value.endswith((" ", "-", "/")):
                        merged_value += " "
                    merged_value += val
            
            # ì²« ë²ˆì§¸ ì¸ë±ìŠ¤ì— ë³‘í•©ëœ ê°’ ì €ì¥
            merged_row[group[0]] = merged_value
            
            # ë‚˜ë¨¸ì§€ ì¸ë±ìŠ¤ëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •
            for idx in group[1:]:
                merged_row[idx] = ""
    
    return merged_row

def merge_dataframe_cells(df):
    """
    ë°ì´í„°í”„ë ˆì„ ì „ì²´ì— ì…€ ë³‘í•© ë¡œì§ ì ìš©
    """
    if df.empty:
        return df
    
    merged_df = df.copy()
    
    # ê° í–‰ì— ëŒ€í•´ ì…€ ë³‘í•© ì ìš©
    for i in range(len(merged_df)):
        merged_df.iloc[i] = merge_adjacent_cells(merged_df.iloc[i])
    
    return merged_df

def trim_after_reference_note(df):
    for i, row in df.iterrows():
        row_text = "".join(str(cell) for cell in row)
        normalized = re.sub(r"\s+", "", row_text)
        if "ì°¸ê³ ì‚¬í•­" in normalized or "ì°¸ê³ " in normalized or "ë¹„ê³ " in normalized:
            return df.iloc[:i]
    return df

def extract_identifier(df):
    for i in range(len(df)):
        row = df.iloc[i]
        row_text = " ".join(str(cell) for cell in row)
        if "ê³ ìœ ë²ˆí˜¸" in row_text:
            for j in range(i+1, min(i+10, len(df))):
                content = " ".join(str(cell) for cell in df.iloc[j])
                if content.strip().startswith(("[í† ì§€]", "[ê±´ë¬¼]")):
                    return content.strip()
            break
    return "ì•Œìˆ˜ì—†ìŒ"

def keyword_match_partial(cell, keyword):
    if pd.isnull(cell): return False
    return keyword.replace(" ", "") in str(cell).replace(" ", "")

def keyword_match_exact(cell, keyword):
    if pd.isnull(cell): return False
    return re.sub(r"\s+", "", str(cell)) == re.sub(r"\s+", "", keyword)

def merge_split_headers(header_row):
    """ë¶„ë¦¬ëœ í—¤ë”ë¥¼ ë³‘í•©í•˜ëŠ” í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „"""
    # ë¨¼ì € ì¸ì ‘ ì…€ ë³‘í•© ì ìš©
    merged_row = merge_adjacent_cells(header_row)
    
    # ê¸°ì¡´ íŠ¹ì • í‚¤ì›Œë“œ ë³‘í•© ë¡œì§ë„ ìœ ì§€
    split_patterns = {
        "ì£¼ì†Œ": ["ì£¼", "ì†Œ"],
        "ë“±ê¸°ëª…ì˜ì¸": ["ë“±ê¸°", "ëª…ì˜ì¸"],
        "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸": ["ì£¼ë¯¼", "ë“±ë¡ë²ˆí˜¸"],
        "ìµœì¢…ì§€ë¶„": ["ìµœì¢…", "ì§€ë¶„"],
        "ìˆœìœ„ë²ˆí˜¸": ["ìˆœìœ„", "ë²ˆí˜¸"],
        "ë“±ê¸°ëª©ì ": ["ë“±ê¸°", "ëª©ì "],
        "ì ‘ìˆ˜ì •ë³´": ["ì ‘ìˆ˜", "ì •ë³´"],
        "ì£¼ìš”ë“±ê¸°ì‚¬í•­": ["ì£¼ìš”", "ë“±ê¸°ì‚¬í•­"],
        "ëŒ€ìƒì†Œìœ ì": ["ëŒ€ìƒ", "ì†Œìœ ì"]
    }
    
    for target_keyword, split_parts in split_patterns.items():
        found_indices = []
        for part in split_parts:
            for idx, cell_value in merged_row.items():
                cell_str = str(cell_value).strip()
                if cell_str == part:
                    found_indices.append(idx)
                    break
        
        if len(found_indices) == len(split_parts):
            if all(found_indices[i+1] - found_indices[i] <= 3 for i in range(len(found_indices)-1)):
                merged_row[found_indices[0]] = target_keyword
                for idx in found_indices[1:]:
                    merged_row[idx] = ""
    
    return merged_row

def enhanced_keyword_match(header_row, keyword, max_distance=2):
    """ì¸ì ‘í•œ ì…€ë“¤ì„ ê³ ë ¤í•œ í‚¤ì›Œë“œ ë§¤ì¹­"""
    # ë¨¼ì € ì¼ë°˜ì ì¸ ë§¤ì¹­ ì‹œë„
    for idx, cell in header_row.items():
        if keyword_match_partial(cell, keyword):
            return idx
    
    # ë¶„ë¦¬ëœ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œë„
    keyword_chars = list(keyword.replace(" ", ""))
    if len(keyword_chars) <= 1:
        return None
    
    for start_idx, cell in header_row.items():
        if str(cell).strip() == keyword_chars[0]:
            # ì²« ê¸€ìê°€ ë§¤ì¹­ë˜ë©´ ë‹¤ìŒ ê¸€ìë“¤ì„ ì¸ì ‘ ì…€ì—ì„œ ì°¾ê¸°
            current_text = str(cell).strip()
            current_idx = start_idx
            
            for i in range(1, len(keyword_chars)):
                found_next = False
                # ìµœëŒ€ max_distanceê¹Œì§€ ë–¨ì–´ì§„ ì…€ì—ì„œ ë‹¤ìŒ ê¸€ì ì°¾ê¸°
                for offset in range(1, max_distance + 1):
                    next_idx = current_idx + offset
                    if next_idx in header_row:
                        next_cell = str(header_row[next_idx]).strip()
                        if next_cell == keyword_chars[i]:
                            current_text += next_cell
                            current_idx = next_idx
                            found_next = True
                            break
                
                if not found_next:
                    break
            
            # ì „ì²´ í‚¤ì›Œë“œê°€ ë§¤ì¹­ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if current_text == keyword.replace(" ", ""):
                return start_idx
    
    return None

def extract_section_range(df, start_kw, end_kw_list, match_fn):
    df = df.fillna("")
    df.columns = range(df.shape[1])
    start_idx, end_idx = None, len(df)
    for i, row in df.iterrows():
        if any(match_fn(cell, start_kw) for cell in row):
            start_idx = i + 1
            break
    if start_idx is None:
        return pd.DataFrame(), False
    for i in range(start_idx, len(df)):
        row = df.iloc[i]
        if any(any(match_fn(cell, end_kw) for cell in row) for end_kw in end_kw_list):
            end_idx = i
            break
    section = df.iloc[start_idx:end_idx].copy()
    is_empty = section.replace("", pd.NA).dropna(how="all").empty
    return section if not is_empty else pd.DataFrame([["ê¸°ë¡ì—†ìŒ"]]), not is_empty

# ì†Œìœ ì§€ë¶„í˜„í™©(ê°‘êµ¬)ì—ì„œ í•„ìš”í•œ ì—´ì„ ì¶”ì¶œ
def extract_named_cols(section, col_keywords):
    if section.empty:
        return pd.DataFrame([["ê¸°ë¡ì—†ìŒ"]])
    
    # ì „ì²´ ì„¹ì…˜ì— ì…€ ë³‘í•© ì ìš©
    section = merge_dataframe_cells(section)
    
    header_row = section.iloc[0]
    merged_header = merge_split_headers(header_row)
    
    col_map = {}
    for target in col_keywords:
        col_idx = enhanced_keyword_match(merged_header, target)
        if col_idx is not None:
            col_map[target] = col_idx
        else:
            for idx, val in merged_header.items():
                if keyword_match_partial(val, target):
                    col_map[target] = idx
                    break

    # ìµœì¢…ì§€ë¶„ ì²˜ë¦¬ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€
    if "ìµœì¢…ì§€ë¶„" not in col_map:
        idx_ìµœì¢… = None
        idx_ì§€ë¶„ = None
        for idx, val in merged_header.items():
            if str(val).strip() == "ìµœì¢…":
                idx_ìµœì¢… = idx
            if str(val).strip() == "ì§€ë¶„":
                idx_ì§€ë¶„ = idx
        if idx_ìµœì¢… is not None and idx_ì§€ë¶„ is not None and abs(idx_ìµœì¢… - idx_ì§€ë¶„) <= 3:
            col_map["ìµœì¢…ì§€ë¶„"] = (min(idx_ìµœì¢…, idx_ì§€ë¶„), max(idx_ìµœì¢…, idx_ì§€ë¶„))

    rows = []
    for i in range(1, len(section)):
        row = section.iloc[i]
        row_dict = {}
        for key in col_keywords:
            if key == "ìµœì¢…ì§€ë¶„":
                if isinstance(col_map.get("ìµœì¢…ì§€ë¶„"), tuple):
                    idx1, idx2 = col_map["ìµœì¢…ì§€ë¶„"]
                    val1 = str(row.get(idx1, "")).strip()
                    val2 = str(row.get(idx2, "")).strip()
                    if val1 and val2:
                        row_dict[key] = val1 + val2
                    else:
                        row_dict[key] = val1 or val2
                elif isinstance(col_map.get("ìµœì¢…ì§€ë¶„"), int):
                    idx = col_map["ìµœì¢…ì§€ë¶„"]
                    val1 = str(row.get(idx, "")).strip()
                    val2 = ""
                    if (idx + 1) in row and not str(merged_header.get(idx + 1, "")).strip():
                        val2 = str(row.get(idx + 1, "")).strip()
                    if val1 and val2:
                        row_dict[key] = val1 + val2
                    else:
                        row_dict[key] = val1 or val2
                else:
                    row_dict[key] = ""
            elif key in col_map:
                row_dict[key] = row.get(col_map[key], "")
            else:
                row_dict[key] = ""
        
        # ë“±ê¸°ëª…ì˜ì¸ê³¼ ì£¼ë¯¼ë²ˆí˜¸ ë¶„ë¦¬ ì²˜ë¦¬
        if "ë“±ê¸°ëª…ì˜ì¸" in row_dict and "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸" in col_keywords:
            owner_text = str(row_dict["ë“±ê¸°ëª…ì˜ì¸"]).strip()
            
            # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ê°€ ë“±ê¸°ëª…ì˜ì¸ í•„ë“œì— ìˆëŠ” ê²½ìš°
            jumin = extract_jumin_number(owner_text)
            if jumin:
                # ì£¼ë¯¼ë²ˆí˜¸ëŠ” ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ í•„ë“œì— ë„£ê³ , ë“±ê¸°ëª…ì˜ì¸ì—ì„œëŠ” ì œê±°
                row_dict["(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸"] = jumin
                row_dict["ë“±ê¸°ëª…ì˜ì¸"] = owner_text.replace(jumin, "").strip()
        
        rows.append(row_dict)
    return pd.DataFrame(rows)

def find_keyword_header(section, col_keywords, max_search_rows=15):
    section = section.fillna("").astype(str)
    for i in range(min(max_search_rows, len(section))):
        row = section.iloc[i]
        match_count = sum(any(keyword_match_exact(cell, kw) for cell in row) for kw in col_keywords)
        if match_count >= 3:
            return i, row
    return None, None

def find_col_index(header_row, keyword):
    for idx, val in header_row.items():
        if keyword_match_exact(val, keyword):
            return idx
    return None

# ì†Œìœ ê¶Œì‚¬í•­ (ê°‘êµ¬)ì™€ ì—ì„œ í•„ìš”í•œ ì—´ ì¶”ì¶œ
def extract_precise_named_cols(section, col_keywords):
    # ì „ì²´ ì„¹ì…˜ì— ì…€ ë³‘í•© ì ìš©
    section = merge_dataframe_cells(section)
    
    header_idx, header_row = find_keyword_header(section, col_keywords)
    if header_idx is None:
        header_row = merge_split_headers(section.iloc[0])
        start_row = 1
    else:
        header_row = merge_split_headers(header_row)
        start_row = header_idx + 1
    
    col_map = {key: find_col_index(header_row, key) for key in col_keywords if find_col_index(header_row, key) is not None}
    if not col_map:
        return pd.DataFrame([["ê¸°ë¡ì—†ìŒ"]])
    
    rows = []
    for i in range(start_row, len(section)):
        row = section.iloc[i]
        row_dict = {key: row[col_map[key]] if col_map[key] in row else "" for key in col_map}
        rows.append(row_dict)
    return pd.DataFrame(rows)
def merge_same_row_if_amount_separated(df):
    df = df.copy()
    for i in range(len(df) - 1):
        row = df.iloc[i]
        main = str(row["ì£¼ìš”ë“±ê¸°ì‚¬í•­"])

        if "ì±„ê¶Œìµœê³ ì•¡" in main:
            # í˜„ì¬ í–‰ê³¼ ë‹¤ìŒ í–‰ ëª¨ë‘ ë³‘í•© í…ìŠ¤íŠ¸ êµ¬ì„±
            combined_row = list(row.values) + list(df.iloc[i + 1].values)
            combined_text = " ".join(str(x) for x in combined_row if pd.notnull(x))

            # ê¸ˆì•¡ íŒ¨í„´ ì¶”ì¶œ
            match = re.search(r"ê¸ˆ[\d,]+ì›", combined_text)
            if match and match.group(0) not in main:
                df.at[i, "ì£¼ìš”ë“±ê¸°ì‚¬í•­"] = main + " " + match.group(0)
    return df
def is_jumin_number(text):
    """
    ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŒ¨í„´ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ: 123456-1234567 ë˜ëŠ” 123456-*******
    """
    if not isinstance(text, str):
        return False
    
    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŒ¨í„´ (ìˆ«ì6ìë¦¬-ìˆ«ìë˜ëŠ”*)
    pattern = re.compile(r'\d{6}-[\d\*]+')
    return bool(re.search(pattern, text))

def extract_jumin_number(text):
    """
    ë¬¸ìì—´ì—ì„œ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŒ¨í„´ì„ ì¶”ì¶œ
    """
    if not isinstance(text, str):
        return ""
    
    pattern = re.compile(r'\d{6}-[\d\*]+')
    match = re.search(pattern, text)
    return match.group(0) if match else ""

if run_button and uploaded_zip:
    temp_dir = tempfile.mkdtemp()
    szj_list, syg_list, djg_list = [], [], []

    with zipfile.ZipFile(uploaded_zip, "r") as z:
        z.extractall(temp_dir)

    # âœ… í•˜ìœ„ í´ë” í¬í•¨ ëª¨ë“  .xlsx íƒìƒ‰
    excel_files = []
    for root, _, files in os.walk(temp_dir):
        for f in files:
            if f.lower().endswith(".xlsx"):
                excel_files.append(os.path.join(root, f))

    for path in excel_files:
        try:
            xls = pd.ExcelFile(path)
            df = xls.parse(xls.sheet_names[0]).fillna("")
            name = extract_identifier(df)

            szj_sec, has_szj = extract_section_range(df, "ì†Œìœ ì§€ë¶„í˜„í™©", ["ì†Œìœ ê¶Œ", "ì €ë‹¹ê¶Œ"], match_fn=keyword_match_partial)
            syg_sec, has_syg = extract_section_range(df, "ì†Œìœ ê¶Œ.*ì‚¬í•­", ["ì €ë‹¹ê¶Œ"], match_fn=keyword_match_exact)
            djg_sec, has_djg = extract_section_range(df, "3.(ê·¼)ì €ë‹¹ê¶Œë°ì „ì„¸ê¶Œë“±(ì„êµ¬)", ["ì°¸ê³ ", "ë¹„ê³ ", "ì´ê³„", "ì „ì‚°ìë£Œ"], match_fn=keyword_match_exact)

            if has_szj:
                szj_df = extract_named_cols(szj_sec, ["ë“±ê¸°ëª…ì˜ì¸", "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸", "ìµœì¢…ì§€ë¶„", "ì£¼ì†Œ", "ìˆœìœ„ë²ˆí˜¸"])
                
                # ë°ì´í„° í›„ì²˜ë¦¬ - ë“±ê¸°ëª…ì˜ì¸ê³¼ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ì •ë¦¬
                for idx, row in szj_df.iterrows():
                    # ë“±ê¸°ëª…ì˜ì¸ì—ì„œ ì£¼ë¯¼ë²ˆí˜¸ íŒ¨í„´ì´ ìˆìœ¼ë©´ ë¶„ë¦¬
                    if pd.notna(row["ë“±ê¸°ëª…ì˜ì¸"]):
                        jumin = extract_jumin_number(str(row["ë“±ê¸°ëª…ì˜ì¸"]))
                        if jumin:
                            szj_df.at[idx, "(ì£¼ë¯¼)ë“±ë¡ë²ˆí˜¸"] = jumin
                            szj_df.at[idx, "ë“±ê¸°ëª…ì˜ì¸"] = str(row["ë“±ê¸°ëª…ì˜ì¸"]).replace(jumin, "").strip()
                
                szj_df.insert(0, "íŒŒì¼ëª…", name)
                szj_list.append(szj_df)
            else:
                szj_list.append(pd.DataFrame([[name, "ê¸°ë¡ì—†ìŒ"]], columns=["íŒŒì¼ëª…", "ë“±ê¸°ëª…ì˜ì¸"]))

            if has_syg:
                syg_df = extract_precise_named_cols(syg_sec, ["ìˆœìœ„ë²ˆí˜¸", "ë“±ê¸°ëª©ì ", "ì ‘ìˆ˜ì •ë³´", "ì£¼ìš”ë“±ê¸°ì‚¬í•­", "ëŒ€ìƒì†Œìœ ì"])
                syg_df.insert(0, "íŒŒì¼ëª…", name)
                syg_list.append(syg_df)
            else:
                syg_list.append(pd.DataFrame([[name, "ê¸°ë¡ì—†ìŒ"]], columns=["íŒŒì¼ëª…", "ìˆœìœ„ë²ˆí˜¸"]))

            if has_djg:
                djg_df = extract_precise_named_cols(djg_sec, ["ìˆœìœ„ë²ˆí˜¸", "ë“±ê¸°ëª©ì ", "ì ‘ìˆ˜ì •ë³´", "ì£¼ìš”ë“±ê¸°ì‚¬í•­", "ëŒ€ìƒì†Œìœ ì"])
                djg_df = merge_same_row_if_amount_separated(djg_df)  # âœ… ì—¬ê¸°ì— ë³‘í•© í•¨ìˆ˜ í˜¸ì¶œ ì¶”ê°€
                djg_df = trim_after_reference_note(djg_df)
                djg_df.insert(0, "íŒŒì¼ëª…", name)
                djg_list.append(djg_df)
            else:
                djg_list.append(pd.DataFrame([[name, "ê¸°ë¡ì—†ìŒ"]], columns=["íŒŒì¼ëª…", "ìˆœìœ„ë²ˆí˜¸"]))
        except Exception as e:
            pass  # ë˜ëŠ” logging.warning(...) ë“±ìœ¼ë¡œ ë¡œê¹…ë§Œ
    wb = Workbook()
    for sheetname, data in zip(
        ["1. ì†Œìœ ì§€ë¶„í˜„í™© (ê°‘êµ¬)", "2. ì†Œìœ ê¶Œì‚¬í•­ (ê°‘êµ¬)", "3. ì €ë‹¹ê¶Œì‚¬í•­ (ì„êµ¬)"],
        [szj_list, syg_list, djg_list]
    ):
        ws = wb.create_sheet(title=sheetname)
        if data:
            df = pd.concat(data, ignore_index=True)
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
        else:
            ws.append(["ê¸°ë¡ì—†ìŒ"])

    wb.remove(wb["Sheet"])
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
        wb.save(tmp.name)
        st.success("âœ… ë¶„ì„ ì™„ë£Œ! ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", data=open(tmp.name, "rb"), file_name="ë“±ê¸°ì‚¬í•­_í†µí•©_ì‹œíŠ¸ë³„êµ¬ì„±.xlsx")
